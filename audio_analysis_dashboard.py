import streamlit as st
import pandas as pd
import plotly.express as px
import torch
import librosa
from PIL import Image
from transformers import Wav2Vec2Processor, Wav2Vec2ForSequenceClassification

# Charger le mod√®le et le processeur pour la pr√©diction
def load_model_and_processor(model_path, processor_path='facebook/wav2vec2-base'):
    model = Wav2Vec2ForSequenceClassification.from_pretrained(model_path)
    processor = Wav2Vec2Processor.from_pretrained(processor_path)
    model.eval()
    return model, processor

# Pr√©diction de sentiment √† partir d'un fichier audio
def predict_sentiment(audio_path, model, processor, inverse_label_map, max_length=32000):
    # Charger et traiter l'audio
    speech, sr = librosa.load(audio_path, sr=16000)
    speech = speech[:max_length] if len(speech) > max_length else np.pad(speech, (0, max_length - len(speech)), 'constant')
    inputs = processor(speech, sampling_rate=16000, return_tensors='pt', padding=True)
    input_values = inputs.input_values
    # Obtenir les pr√©dictions du mod√®le
    with torch.no_grad():
        outputs = model(input_values)
    logits = outputs.logits
    predicted_class = logits.argmax(dim=-1).item()
    print(f"le predicted_class est ::::::::::::::::{predicted_class}")
    sentiment = inverse_label_map[predicted_class]
    print(f"le sentiment est ::::::::::::::::{sentiment}")
    return sentiment

def predict_sentiment_load(audio, model, processor, inverse_label_map_audio, max_length=32000):
    # Charger et traiter l'audio
    speech = librosa.load(audio, sr=16000)
    speech = speech[:max_length] if len(speech) > max_length else np.pad(speech, (0, max_length - len(speech)), 'constant')
    inputs = processor(speech, sampling_rate=16000, return_tensors='pt', padding=True)
    input_values = inputs.input_values
    # Obtenir les pr√©dictions du mod√®le
    with torch.no_grad():
        outputs = model(input_values)
    logits = outputs.logits
    predicted_class = logits.argmax(dim=-1).item()
    print(f"le predicted_class est ::::::::::::::::{predicted_class}")
    sentiment = inverse_label_map_audio[predicted_class]
    print(f"le sentiment est ::::::::::::::::{sentiment}")
    return sentiment

# Fonction d'analyse exploratoire
def exploratory_analysis(df):
    st.subheader("üîç Analyse exploratoire des donn√©es")
    st.write("Statistiques descriptives des donn√©es :")
    st.write(df.describe(include='all'))

    emotion_counts = df['Emotion'].value_counts()
    fig_emotion = px.pie(values=emotion_counts, names=emotion_counts.index, title="R√©partition des √©motions", color_discrete_sequence=px.colors.qualitative.Set3)
    st.plotly_chart(fig_emotion, use_container_width=True)

    intensity_counts = df['Emotion intensity'].value_counts()
    fig_intensity = px.bar(x=intensity_counts.index, y=intensity_counts.values, title="Intensit√© des √©motions", labels={'x': 'Intensit√©', 'y': 'Nombre'}, color=intensity_counts.index, color_discrete_sequence=px.colors.qualitative.Pastel)
    st.plotly_chart(fig_intensity, use_container_width=True)

    gender_counts = df['Gender'].value_counts()
    fig_gender = px.bar(x=gender_counts.index, y=gender_counts.values, title="R√©partition des genres", labels={'x': 'Genre', 'y': 'Nombre'}, color=gender_counts.index, color_discrete_sequence=px.colors.qualitative.Prism)
    st.plotly_chart(fig_gender, use_container_width=True)

    fig_emotion_intensity = px.histogram(df, x='Emotion', color='Emotion intensity', barmode='group', title="R√©partition des √©motions par intensit√©", color_discrete_sequence=px.colors.qualitative.Set2)
    st.plotly_chart(fig_emotion_intensity, use_container_width=True)

    fig_emotion_gender = px.histogram(df, x='Emotion', color='Gender', barmode='group', title="R√©partition des √©motions par genre", color_discrete_sequence=px.colors.qualitative.Dark2)
    st.plotly_chart(fig_emotion_gender, use_container_width=True)

    reduced_emotion_counts = df['Emotion_Category'].value_counts().sort_index()
    fig_reduced_emotion = px.pie(values=reduced_emotion_counts, names=reduced_emotion_counts.index, title="R√©partition des √©motions r√©duites", color_discrete_sequence=px.colors.qualitative.Vivid)
    st.plotly_chart(fig_reduced_emotion, use_container_width=True)

    fig_reduced_emotion_gender = px.histogram(df, x='Emotion_Category', color='Gender', barmode='group', title="R√©partition des √©motions r√©duites par genre", color_discrete_sequence=px.colors.qualitative.Safe)
    st.plotly_chart(fig_reduced_emotion_gender, use_container_width=True)

    st.write("Exemples de donn√©es :")
    st.dataframe(df.sample(5))

# Fonction principale pour afficher le dashboard
def main():
    st.set_page_config(page_title="Dashboard d'Analyse de Sentiment Audio", layout="wide")
    left_co, cent_co, last_co = st.columns(3)
    with cent_co:
        st.image("images/banner.jpg", width=400)

    st.sidebar.title("Options du Dashboard")
    st.sidebar.write("Utilisez cette barre pour naviguer dans les options.")
    
    # Charger les donn√©es fictives
    df = pd.read_csv('ravdess_streamlit.csv')
    df_audio = df.head(43)

    # Charger le mod√®le et le processeur pour les pr√©dictions
    checkpoint_dir = "./results/checkpoint-459"  # Remplacez par le chemin de votre mod√®le
    model, processor = load_model_and_processor(checkpoint_dir)
    inverse_label_map = {0: 'neutral', 1: 'positif', 2: 'positif', 3: 'negatif', 4: 'negatif', 5: 'negatif'}  # Remplacez par votre map
    #inverse_label_map_audio = {'neutral': 0, 'calm': 'positif', 'happy': 'positif', 'sad': "negatif", 'angry': "negatif", 'fear': "negatif"}  # Remplacez par votre map

    # Afficher un widget pour s√©lectionner l'analyse ou la pr√©diction
    option = st.sidebar.selectbox("Choisissez une option :", ["Analyse exploratoire", "Pr√©diction de sentiment", "Pr√©dire sentiment sur fichier audio"])

    if option == "Analyse exploratoire":
        exploratory_analysis(df)

    elif option == "Pr√©diction de sentiment":
        st.subheader("üéß Pr√©diction du sentiment pour un fichier audio")
        audio_id = st.sidebar.selectbox("Choisir un ID audio :", df_audio['Path'].unique())
        audio_info = df[df['Path'] == audio_id].iloc[0]

        st.write("### Informations sur l'audio s√©lectionn√© :")
        st.write(f"- **Genre :** {audio_info['Gender']}")
        st.write(f"- **Emotion r√©elle :** {audio_info['Emotion_Category']}")

        if st.button("Pr√©dire le sentiment"):
            sentiment = predict_sentiment(audio_id, model, processor, inverse_label_map)
            st.write(f"### Le sentiment pr√©dit pour cet audio est : **{sentiment}**")
            # Afficher une image de sentiment si la pr√©diction est effectu√©e
            if sentiment:
                # Charger les images locales pour chaque sentiment
                sentiment_images = {
                    "positif": Image.open("images/positif.jpg"),
                    "neutral": Image.open("images/neutre.jpg"),
                    "negatif": Image.open("images/negatif.jpg")
                }
                st.image(sentiment_images[sentiment], width=150, caption=f"Sentiment : {sentiment}")


    elif option == "Pr√©dire sentiment sur fichier audio":
        st.subheader("üé§ Pr√©diction de sentiment pour un fichier audio upload√©")
        audio_file = st.file_uploader("T√©l√©chargez un fichier audio", type=["wav", "mp3"])

        if audio_file is not None:
            with open("uploaded_audio.wav", "wb") as f:
                f.write(audio_file.getbuffer())
            st.audio(audio_file, format="audio/wav")

            if st.button("Pr√©dire le sentiment"):
                sentiment = predict_sentiment("uploaded_audio.wav", model, processor, inverse_label_map)
                st.write(f"### Le sentiment pr√©dit pour cet audio est : **{sentiment}**")
                # Afficher une image de sentiment si la pr√©diction est effectu√©e
                if sentiment:
                    # Charger les images locales pour chaque sentiment
                    sentiment_images = {
                        "positif": Image.open("images/positif.jpg"),
                        "neutral": Image.open("images/neutre.jpg"),
                        "negatif": Image.open("images/negatif.jpg")
                    }
                    st.image(sentiment_images[sentiment], width=150, caption=f"Sentiment : {sentiment}")


if __name__ == "__main__":
    main()